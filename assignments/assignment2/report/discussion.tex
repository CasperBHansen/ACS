%==============================================================================%
% DISCUSSION                                                                   %
%==============================================================================%

\newpage
\section{Discussion on Concurrent Implementation}

\subsection{Description of implementation}
Our implementation maintains a table of locks which binds an ISBN to an
associated lock. In addition to this, we maintain a global lock, which acts as
a safeguard on the lock table. Its purpose is to ensure that we only lock whole
sets of books at a time. Obtaining write locks concurrently is therefore possible
if and only if the sets of books do not intersect. This enforces conflict
resolution. The read lock is more permissive since it's a shared lock. We also lock the global lock in shared mode when acquiring shared locks on the books. This ensures a write is possible while reading if it wants to modify a book not currently being read. This begs the question if it is possible to have the phantom problem in the {\tt getBooks} method. We would argue that this cannot happen since all read functions read only the books once while all the books are locked, meaning the snapshot either happens before-or-after some read. This also ensures before-or-after atomicity.

\begin{itemize}
\item Test 1: Before-or-after atomicity, dirty-write.
\item Test 2: Before-or-after atomicity, dirt-read.
\item Test Time:
\item TestBuyTwice:
\item TestEditorPicks: Before-or-after atomicity, dirty-reads
\end{itemize}

\subsection{Locking protocol correctness}
We reason that our locking protocol holds, because we lock sets of books, rather
than acquiring individual locks as they are needed. Our implementation ensures
that we cannot obtain a subset of locks for a given operation, without stalling
if one or more of the locks needed cannot be acquired, if it is already in use.
Hence any operation with intersecting sets of books must wait for the previous
operation to finish before the next operation can proceed.

-----

Since we acquire exclusive locks when before writing, and shared locks before reading, and release said locks when done, we argue this does in fact follow a Strict 2PL protocol. In particular, we use a two-phase locking mechanism (not to be confused with the 2PL protocol) where we have a single global lock which a read (respectively write) operation first locks in shared (respectively exclusive) mode when locking the individual locks of the books used in the operation. When all books are locked, the global lock is released. we use a exclusive lock on the books we want to write to or change individually in all cases, and only release the locks when done. For reading, since we want multiple read to be possible at the same time, we use a shared lock on each individual book when wanting to read and release when done.

\subsection{Deadlocks}
Because of the way we have chosen to acquire locks in sets, rather than one by
one, we argue that no deadlocks should be able to occur. Any reads are allowed
to perform their operations concurrently, but once a write operation is set in
motion we lock the table of locks, acquire all the write locks needed, and then
release the table lock. So any subsequent read/write operation would stall at
acquiring its locks, if the sets of entries of the former and the latter
intersect, effectively letting the former finish before the latter is allowed
to proceed. In short, no.

\subsection{Scalability and bottlenecks}
Definitely. As described before, because of how we've chosen to prioritise
correctness over concurrency, our solution suffers the botteneck of intersecting
sets not being allowed to be processed concurrently.
One obvious bottleneck is the global locks.

\subsection{Overhead}
We consider our solution to pay a lot of overhead in exchange for correctness.
Our solution can cause halting of several operations as a consequence of only
allowing for operations on sets of books at a time --- or more explicitly, we
only allow lock acquisition for sets of locks.


